import argparse
from functools import partial
import jax
import jax.numpy as jnp
import numpy as np
from flax.core import freeze
from networks.conn_snn import ConnSNN

def run_simulation(model_def, params, fixed_weights, num_steps, x_seq):
    # x_seq: (Time, In_Dims)
    
    @partial(jax.jit, static_argnums=(0,))
    def jit_apply(model_def_static, carry, x):
        variables = {'params': params, 'fixed_weights': fixed_weights}
        # ä½¿ç”¨ä¿®æ”¹åçš„ ConnSNNï¼Œå®ƒæ¥å—æ—¶åºè¾“å…¥ (Time, In)
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä¸éœ€è¦ scanï¼Œå› ä¸º ConnSNN.__call__ å†…éƒ¨å·²ç»åŒ…å«äº† scan
        final_carry, output = model_def_static.apply(variables, carry, x)
        return output

    key = jax.random.PRNGKey(0)
    batch_size = 1 # æˆ‘ä»¬åªæµ‹ä¸€ä¸ªæ ·æœ¬ï¼Œä½† ConnSNN éœ€è¦è¾“å…¥å½¢çŠ¶åŒ¹é…
    # æ³¨æ„ï¼švmap æ¨¡å¼ä¸‹ ConnSNN æœŸæœ› (Time, In)ï¼ŒBatch æ¨¡å¼ä¸‹æœŸæœ› (Batch, Time, In)
    # ä¸ºäº†æ¨¡æ‹Ÿ ec.py çš„è¡Œä¸ºï¼Œæˆ‘ä»¬è¿™é‡Œä¸ä½¿ç”¨ Batch ç»´åº¦ï¼Œç›´æ¥æ¨¡æ‹Ÿ vmap å†…éƒ¨çš„ä¸€æ¬¡è°ƒç”¨
    
    # é‡æ–°åˆå§‹åŒ–ä¸€ä¸ªä¸å¸¦ Batch çš„ carry
    # ConnSNN.initial_carry é€šå¸¸è¿”å› (Batch, N)ï¼Œæˆ‘ä»¬éœ€è¦ (N,)
    carry_batch = model_def.initial_carry(key, 1)
    carry = jax.tree_map(lambda x: x[0], carry_batch)

    output = jit_apply(model_def, carry, x_seq)
    return output

def main(args):
    print(f"--- è¯Šæ–­è¾“å‡º: K_in={args.K_in}, K_h={args.K_h}, K_out={args.K_out} ---")
    
    # æ¨¡æ‹Ÿ 14x14 = 196 è¾“å…¥
    in_dims = 196
    time_steps = 200 # 100ms

    try:
        physics_data = np.load('neuron_physics.npz')
        num_neurons = int(physics_data['num_neurons'])
        exc_ratio = float(physics_data['excitatory_ratio'])
        tau_vm_vec = tuple(physics_data['tau_Vm'].tolist())
    except FileNotFoundError:
        print("é”™è¯¯: æ‰¾ä¸åˆ° neuron_physics.npz")
        return

    # å®ä¾‹åŒ–æ¨¡å‹
    model = ConnSNN(
        out_dims=10,
        num_neurons=num_neurons,
        excitatory_ratio=exc_ratio,
        tau_Vm_vector=tau_vm_vec,
        K_in=args.K_in,
        K_h=args.K_h,
        K_out=args.K_out, # [å…³é”®] ä¼ å…¥ K_out
        dt=0.5
    )

    # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
    key = jax.random.PRNGKey(42)
    
    # 1. æ¨¡æ‹Ÿæ³Šæ¾è¾“å…¥ (Time, 196)
    # å‡è®¾è¾“å…¥å¼ºåº¦ 0.5
    input_probs = jnp.full((time_steps, in_dims), 0.1) 
    x_seq = jax.random.bernoulli(key, input_probs).astype(jnp.float32)
    
    # 2. æ¨¡æ‹Ÿå‚æ•° (ç¨€ç–)
    # è¿™é‡Œæˆ‘ä»¬åªå…³å¿ƒè¾“å‡ºå€¼çš„é‡çº§ï¼Œéšæœºç¨€ç–å³å¯
    dummy_params = freeze({
        'kernel_in': jax.random.bernoulli(key, 0.1, (2*in_dims, num_neurons)),
        'kernel_h': jax.random.bernoulli(key, 0.1, (num_neurons, num_neurons)),
        'kernel_out': jax.random.bernoulli(key, 0.5, (num_neurons, 10))
    })
    dummy_fixed_weights = freeze({'dummy': None})

    # è¿è¡Œ
    try:
        logits = run_simulation(model, dummy_params, dummy_fixed_weights, time_steps, x_seq)
        
        print("\n=== è¯Šæ–­ç»“æœ ===")
        print(f"Logits (åŸå§‹è¾“å‡º): {logits}")
        print(f"Logits Mean: {jnp.mean(logits):.6f}, Max: {jnp.max(logits):.6f}, Min: {jnp.min(logits):.6f}")
        print(f"Logits Range (Max-Min): {jnp.max(logits) - jnp.min(logits):.6f}")
        
        probs = jax.nn.softmax(logits)
        print(f"Softmax Probs: {probs}")
        print(f"Max Prob: {jnp.max(probs):.4f} (éšæœºçŒœæµ‹æ˜¯ 0.1)")
        
        if jnp.max(probs) < 0.15:
            print("âŒ è¾“å‡ºåŒºåˆ†åº¦å¤ªä½ï¼Softmax åå‡ ä¹æ˜¯å‡åŒ€åˆ†å¸ƒã€‚")
            print("ğŸ’¡ å»ºè®®: å¤§å¹…å¢åŠ  K_out")
        else:
            print("âœ… è¾“å‡ºåŒºåˆ†åº¦å°šå¯ã€‚")
            
    except Exception as e:
        print(f"è¿è¡Œå‡ºé”™: {e}")
        # import traceback
        # traceback.print_exc()

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--K_in", type=float, default=0.1)
    parser.add_argument("--K_h", type=float, default=0.08)
    parser.add_argument("--K_out", type=float, default=5.0) # é»˜è®¤å€¼
    args = parser.parse_args()
    main(args)
import jax
import jax.numpy as jnp
import numpy as np
import pickle
import os
from tqdm import tqdm

# å¯¼å…¥ä½ çš„æ¨¡å—
from networks.conn_snn import ConnSNN_Selected
from utils.mnist_loader import load_mnist_data

def load_trained_weights(file_path):
    """åŠ è½½æ¨¡å‹å‚æ•°"""
    print(f">>> æ­£åœ¨ä» {file_path} åŠ è½½å‚æ•°...")
    with open(file_path, 'rb') as f:
        data = pickle.load(f)
    return data['params'], data['fixed_weights']

def main():
    # 1. è·¯å¾„è®¾ç½® (è¯·ç¡®ä¿æ–‡ä»¶ååŒ¹é…)
    MODEL_PATH = 'trained_model.pkl'
    PHYSICS_PATH = 'neuron_physics.npz'
    NEURONS_CSV = '../dataset/mice_unnamed/neurons.csv.gz'

    if not os.path.exists(MODEL_PATH):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ {MODEL_PATH}")
        return

    # 2. åŠ è½½ MNIST æµ‹è¯•é›† (10,000 å¼ å›¾ç‰‡)
    print(">>> æ­£åœ¨åŠ è½½ MNIST æµ‹è¯•é›†...")
    test_images, test_labels = load_mnist_data('test') # ä½¿ç”¨ 'test' åˆ†å‰²
    num_test = test_images.shape[0]

    # 3. åŠ è½½ç”Ÿç‰©ç‰©ç†å‚æ•° (Tau ç­‰)
    print(">>> åŠ è½½ç‰©ç†å‚æ•°...")
    phys = np.load(PHYSICS_PATH)
    bio_tau_Vm = tuple(phys['tau_Vm'].tolist())
    num_neurons = int(phys['num_neurons'])
    exc_ratio = float(phys['excitatory_ratio'])

    # 4. åˆå§‹åŒ–ç½‘ç»œå®šä¹‰
    # æ³¨æ„ï¼šè¿™äº›å‚æ•°å¿…é¡»ä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´ï¼
    network = ConnSNN_Selected(
        out_dims=10,
        num_neurons=num_neurons,
        excitatory_ratio=exc_ratio,
        tau_Vm_vector=bio_tau_Vm,
        K_in=2.0,   # è¯·ç¡®ä¿è¿™é‡Œæ˜¯ä½ è®­ç»ƒæˆåŠŸæ—¶çš„ K å€¼
        K_h=0.05, 
        K_out=200.0,
        dt=0.5,
        readout_indices=tuple(range(10)), # å‡è®¾ä½ è®­ç»ƒæ—¶ç”¨çš„æ˜¯ get_l5_excitatory_indices çš„ç»“æœ
        readout_start_step=300,
        readout_end_step=400
    )

    # 5. åŠ è½½å¹¶è½¬æ¢è¿›åŒ–å‡ºçš„å‚æ•°
    raw_params, fixed_weights = load_trained_weights(MODEL_PATH)
    # [å…³é”®æ­¥éª¤] å°†è¿æ¥æ¦‚ç‡è½¬æ¢ä¸ºç¡®å®šçš„å¸ƒå°”è¿æ¥ (Inference Mode)
    inference_params = jax.tree_util.tree_map(lambda p: p > 0.5, raw_params)

    # 6. å®šä¹‰ JIT åŠ é€Ÿçš„æ‰¹æ¬¡æ¨ç†å‡½æ•°
    @jax.jit
    def batch_inference(images):
        """
        images shape: (Batch, Features)
        è¿”å›: (Batch, Out_Dims) çš„ Logits
        """
        batch_size = images.shape[0]
        # ç”Ÿæˆæ—¶åºæ³Šæ¾è„‰å†² [Batch, Time=400, Features=196]
        # ä¿æŒä¸ MnistEnv é€»è¾‘ä¸€è‡´
        probs = jnp.expand_dims(images * (200.0 * 0.5 / 1000.0), 1)
        probs = jnp.repeat(probs, 400, axis=1)
        
        # ä½¿ç”¨å›ºå®šçš„ Key ä¿è¯æ¨ç†çš„å¯å¤ç°æ€§
        spikes = jax.random.bernoulli(jax.random.PRNGKey(0), probs).astype(jnp.float32)
        
        # åˆå§‹åŒ– carry
        init_carry = network.initial_carry(jax.random.PRNGKey(0), batch_size)
        
        # è¿è¡Œç½‘ç»œ (vmap å¤„ç† batch)
        vmapped_apply = jax.vmap(network.apply, in_axes=({'params': None, 'fixed_weights': None}, 0, 0))
        _, logits = vmapped_apply({'params': inference_params, 'fixed_weights': fixed_weights}, init_carry, spikes)
        
        return logits

    # 7. åˆ†æ‰¹è¿è¡Œæ¨ç† (é˜²æ­¢æ˜¾å­˜çˆ†ç‚¸)
    BATCH_SIZE = 100
    all_preds = []
    
    print(f">>> å¼€å§‹å¯¹ {num_test} å¼ æµ‹è¯•å›¾è¿›è¡Œæ¨ç†...")
    for i in tqdm(range(0, num_test, BATCH_SIZE)):
        batch_img = test_images[i : i + BATCH_SIZE]
        logits = batch_inference(batch_img)
        preds = jnp.argmax(logits, axis=-1)
        all_preds.append(preds)

    # 8. è®¡ç®—å‡†ç¡®ç‡
    final_preds = jnp.concatenate(all_preds)
    accuracy = jnp.mean(final_preds == test_labels)

    print("\n" + "="*30)
    print(f"ğŸ“Š å…¨é‡æµ‹è¯•é›†å‡†ç¡®ç‡: {accuracy*100:.2f}%")
    print("="*30)

    # æ‰“å°ä¸€äº›æ··æ·†æƒ…å†µ
    for i in range(10):
        class_mask = (test_labels == i)
        class_acc = jnp.mean(final_preds[class_mask] == i)
        print(f"æ•°å­— {i} çš„å‡†ç¡®ç‡: {class_acc*100:.1f}%")

if __name__ == "__main__":
    main()
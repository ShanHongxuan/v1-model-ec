import jax
import jax.numpy as jnp
import numpy as np
import optax
from flax import linen as nn
from omegaconf import OmegaConf
from tqdm import tqdm

# å¼•å…¥ä½ çš„æ¨¡å—
from networks.conn_snn import ConnSNN
# å‡è®¾è¿™äº›éƒ½åœ¨å½“å‰ç›®å½•
from networks import NETWORKS 

# ================= 1. å®šä¹‰ä¸€ä¸ªâ€œä½œå¼Šâ€ç¯å¢ƒ =================
# è¿™ä¸ªç¯å¢ƒæ°¸è¿œåªè¾“å‡ºåŒä¸€å¼ å›¾ï¼Œæ ‡ç­¾æ°¸è¿œæ˜¯ 0
class OverfitEnv:
    def __init__(self, n_features=196, n_steps=200, input_hz=100.0, dt=0.5):
        self.n_features = n_features
        self.n_steps = n_steps
        self.prob_per_step = input_hz * (dt / 1000.0)
        
        # å›ºå®šç”Ÿæˆä¸€å¼ â€œå‡å›¾â€ï¼šå‰åŠéƒ¨åˆ†æ˜¯äº®çš„ï¼ŒååŠéƒ¨åˆ†æ˜¯æš—çš„
        # è¿™æ˜¯ä¸€ä¸ªéå¸¸å¼ºçš„ç‰¹å¾
        img = np.zeros(n_features)
        img[:n_features//2] = 1.0 
        self.fixed_image = jnp.array(img)
        self.fixed_label = 1 # æ°¸è¿œæ˜¯ç±»åˆ« 0

    def reset(self, rng):
        # å¿½ç•¥ rngï¼Œç”Ÿæˆå›ºå®šçš„æ³Šæ¾åºåˆ—
        # å½¢çŠ¶: (Batch=1, Time, Features) -> æˆ‘ä»¬åœ¨å¤–éƒ¨ vmapï¼Œæ‰€ä»¥è¿™é‡Œè¿”å› (Time, Features)
        
        # è¿™é‡Œä¸ºäº†ç®€å•ï¼Œæˆ‘ä»¬ç”šè‡³ä¸ä½¿ç”¨éšæœºæ³Šæ¾ï¼Œç›´æ¥ä½¿ç”¨ç¡®å®šæ€§è¾“å…¥æµ‹è¯•
        # æˆ–è€…æ˜¯å›ºå®šçš„éšæœºç§å­
        rng_fixed = jax.random.PRNGKey(999)
        probs = self.fixed_image * self.prob_per_step
        # æ‰©å±•æ—¶é—´ç»´
        probs = jnp.expand_dims(probs, 0).repeat(self.n_steps, axis=0)
        obs = jax.random.bernoulli(rng_fixed, probs).astype(jnp.float32)
        
        return {
            'obs': obs,
            'label': self.fixed_label
        }

    def step(self, state, action):
        # action æ˜¯ logits
        pred = jnp.argmax(action)
        reward = jnp.where(pred == state['label'], 1.0, 0.0)
        # åŒæ—¶ä¹Ÿè®¡ç®— Softmax å¥–åŠ±ä»¥ä¾¿è§‚å¯Ÿ
        probs = jax.nn.softmax(action)
        soft_reward = probs[state['label']]
        
        return reward, soft_reward

# ================= 2. æç®€è®­ç»ƒå¾ªç¯ =================
def main():
    print("=== å¼€å§‹è¿‡æ‹Ÿåˆæµ‹è¯• (Overfit Test) ===")
    
    # --- é…ç½® ---
    POP_SIZE = 128 # å°ç§ç¾¤
    LR = 0.2
    GENS = 200
    
    # ä½¿ç”¨ä½ è®¤ä¸ºâ€œåº”è¯¥å·¥ä½œâ€çš„å‚æ•°
    K_IN = 12
    K_H = 1
    K_OUT = 100.0
    
    # æ¨¡æ‹Ÿ ec.py çš„é…ç½®ç»“æ„
    network_config = {
        "out_dims": 10,
        "num_neurons": 509,
        "excitatory_ratio": 0.76,
        "K_in": K_IN,
        "K_h": K_H,
        "K_out": K_OUT,
        "dt": 0.5,
        "tau_Vm_vector": None # ç®€åŒ–ï¼Œå…ˆä¸ç”¨ç”Ÿç‰© Tau
    }
    
    model = ConnSNN(**network_config)
    
    # åˆå§‹åŒ–å‚æ•° (å…¨ 0.5)
    key = jax.random.PRNGKey(0)
    init_obs = jnp.zeros((200, 196)) # Dummy input for init
    
    # [ä¿®æ­£] æ­£ç¡®å¤„ç† initial_carry
    # 1. è·å–å¸¦ Batch çš„åˆå§‹çŠ¶æ€: (Batch, N)
    init_carry_batch = model.initial_carry(key, 1) 
    
    # 2. å»é™¤ Batch ç»´åº¦ï¼Œä½†ä¿ç•™ (v_m, i_syn, rate, spike) çš„å…ƒç»„ç»“æ„
    # è¿™é‡Œçš„ lambda x: x[0] æ˜¯å¯¹å…ƒç»„é‡Œçš„æ¯ä¸ªæ•°ç»„æ“ä½œï¼Œå–ç¬¬0ä¸ªæ ·æœ¬
    init_carry = jax.tree_map(lambda x: x[0], init_carry_batch)
    
    # 3. ä¼ å…¥å®Œæ•´çš„ tuple ç»“æ„è¿›è¡Œåˆå§‹åŒ–
    variables = model.init(key, init_carry, init_obs)
    
    # è¿›åŒ–å‚æ•° (Probabilities)
    params = jax.tree_map(lambda x: jnp.full_like(x, 0.5), variables['params'])
    fixed_weights = variables['fixed_weights']
    
    # ä¼˜åŒ–å™¨
    optimizer = optax.adam(LR)
    opt_state = optimizer.init(params)
    
    # ç¯å¢ƒ
    env = OverfitEnv()
    
    # --- æ ¸å¿ƒå‡½æ•° (JIT) ---
    @jax.jit
    def train_step(rng, current_params, opt_state):
        # 1. é‡‡æ ·å‚æ•° (Binary Masks)
        # noise: 0/1 mask
        noise_keys = jax.random.split(rng, POP_SIZE)
        
        def sample_mask(p, k):
            return jax.random.uniform(k, p.shape) < p
            
        # vmap é‡‡æ ·
        batch_sample = jax.vmap(lambda k: jax.tree_map(lambda p: sample_mask(p, k), current_params))
        binary_params = batch_sample(noise_keys)
        
        # 2. è¯„ä¼° (Evaluation)
        def evaluate_one(bin_param):
            # Reset
            state = env.reset(jax.random.PRNGKey(0)) # å›ºå®šç¯å¢ƒç§å­
            # Forward
            # æ³¨æ„: ConnSNN éœ€è¦ ('params', 'fixed_weights')
            vars_in = {'params': bin_param, 'fixed_weights': fixed_weights}
            carry = model.initial_carry(jax.random.PRNGKey(0), 1)
            # å»æ‰ batch ç»´
            carry = jax.tree_map(lambda x: x[0], carry)
            
            _, output = model.apply(vars_in, carry, state['obs'])
            
            # Reward
            acc, soft_rew = env.step(state, output)
            return acc, soft_rew, output

        # Vmap over population
        rewards, soft_rewards, outputs = jax.vmap(evaluate_one)(binary_params)
        
        # 3. NES æ›´æ–° (Natural Evolution Strategies)
        # ä½¿ç”¨ soft_reward ä½œä¸ºæ¢¯åº¦ä¿¡å·é€šå¸¸æ›´å¥½
        fitness = soft_rewards 
        
        # ç§©å˜æ¢ (Centered Rank)
        ranks = jnp.argsort(jnp.argsort(fitness))
        w = (ranks / (POP_SIZE - 1)) - 0.5
        
        # æ¢¯åº¦ = E[w * (theta - p)]
        # theta æ˜¯ 0/1, p æ˜¯æ¦‚ç‡
        # æ³¨æ„: æˆ‘ä»¬éœ€è¦æŠŠ w å¹¿æ’­åˆ°å‚æ•°å½¢çŠ¶
        def compute_grad(p, theta):
            # theta: (Pop, ...)
            # w: (Pop,)
            w_expanded = w.reshape((-1,) + (1,) * (p.ndim))
            
            # å…³é”®ä¿®æ”¹ï¼štheta.astype(jnp.float32)
            # å¿…é¡»å…ˆè½¬æˆ float æ‰èƒ½è¿›è¡Œå‡æ³•è¿ç®—
            return -jnp.mean(w_expanded * (theta.astype(jnp.float32) - p), axis=0)
            
        grads = jax.tree_map(lambda p, theta: compute_grad(p, theta), current_params, binary_params)
        
        # 4. ä¼˜åŒ–å™¨æ›´æ–°
        updates, new_opt_state = optimizer.update(grads, opt_state)
        new_params = optax.apply_updates(current_params, updates)
        
        # Clip
        new_params = jax.tree_map(lambda x: jnp.clip(x, 0.001, 0.999), new_params)
        
        return new_params, new_opt_state, jnp.mean(rewards), jnp.mean(soft_rewards), outputs[0]

    # --- å¾ªç¯ ---
    rng = jax.random.PRNGKey(42)
    pbar = tqdm(range(GENS))
        # ç”¨äºè®°å½•æ˜¯å¦å·²ç»è¾¾æ ‡è¿‡
    has_reached_target = False
    
    # ç”¨äºå­˜å‚¨æœ€åä¸€æ­¥çš„è¾“å‡º
    final_sample_out = None
    final_acc = 0.0

    for i in pbar:
        rng, step_key = jax.random.split(rng)
        params, opt_state, mean_acc, mean_soft, sample_out = train_step(step_key, params, opt_state)
        
        # æ›´æ–°æœ€åçš„çŠ¶æ€
        final_sample_out = sample_out
        final_acc = mean_acc
        
        probs = jax.nn.softmax(sample_out)
        target_prob = probs[1] # ç›®æ ‡æ˜¯ç±»åˆ« 1 (æ ¹æ®ä¹‹å‰çš„ä¿®æ”¹)
        
        pbar.set_description(f"Acc: {mean_acc:.2f} | Soft: {mean_soft:.3f} | TargetProb: {target_prob:.3f}")
        
        # [ä¿®æ”¹] è¾¾åˆ°ç›®æ ‡åä¸é€€å‡ºï¼Œä»…æ‰“å°æç¤º
        if mean_acc > 0.95 and not has_reached_target:
            has_reached_target = True
            # ä½¿ç”¨ tqdm.write é˜²æ­¢æ‰“ä¹±è¿›åº¦æ¡
            tqdm.write(f"\nâœ¨ ç¬¬ {i} ä»£é¦–æ¬¡è¾¾åˆ°ç›®æ ‡ç²¾åº¦ï¼ç»§ç»­è®­ç»ƒè‡³ç»“æŸ...")
            # return  <-- [å…³é”®ä¿®æ”¹] æ³¨é‡Šæ‰è¿™å°±ä¸ä¼šæå‰é€€å‡ºäº†

    print("\n" + "="*30)
    print("ğŸ è®­ç»ƒæŒ‡å®šæ­¥æ•°å®Œæˆ")
    
    if has_reached_target:
        print("âœ… çŠ¶æ€: æˆåŠŸ (è®­ç»ƒè¿‡ç¨‹ä¸­æ›¾è¾¾åˆ°ç›®æ ‡)")
    else:
        print("âŒ çŠ¶æ€: å¤±è´¥ (ä»æœªè¾¾åˆ°ç›®æ ‡)")

    print(f"æœ€ç»ˆç²¾åº¦ (Final Acc): {final_acc:.4f}")
    print(f"æœ€ç»ˆ Logits:\n{final_sample_out}")
    
    # é¢å¤–åˆ†æä¸€ä¸‹ä¿¡å·å¼ºåº¦
    target_logit = final_sample_out[1]
    other_logits = jnp.delete(final_sample_out, 1)
    avg_noise = jnp.mean(other_logits)
    margin = target_logit - avg_noise
    
    print(f"\nä¿¡å·å¼ºåº¦åˆ†æ:")
    print(f"ç›®æ ‡å¾—åˆ† (Target): {target_logit:.4f}")
    print(f"èƒŒæ™¯å™ªéŸ³ (Avg Noise): {avg_noise:.4f}")
    print(f"ä¿¡å™ªæ¯”å·®å€¼ (Margin): {margin:.4f} (è¶Šå¤§è¶Šå¥½)")
    print("="*30)

if __name__ == "__main__":
    main()